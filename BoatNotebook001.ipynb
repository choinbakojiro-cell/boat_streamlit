{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cece0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.8150\n",
      "Epoch 2, Loss: 1.8081\n",
      "Epoch 3, Loss: 1.8044\n",
      "Epoch 4, Loss: 1.8011\n",
      "Epoch 5, Loss: 1.7962\n",
      "Epoch 6, Loss: 1.7855\n",
      "Epoch 7, Loss: 1.7765\n",
      "Epoch 8, Loss: 1.7618\n",
      "Epoch 9, Loss: 1.7469\n",
      "Epoch 10, Loss: 1.7344\n",
      "Epoch 11, Loss: 1.7146\n",
      "Epoch 12, Loss: 1.6969\n",
      "Epoch 13, Loss: 1.6848\n",
      "Epoch 14, Loss: 1.6593\n",
      "Epoch 15, Loss: 1.6519\n",
      "Epoch 16, Loss: 1.6357\n",
      "Epoch 17, Loss: 1.6322\n",
      "Epoch 18, Loss: 1.6258\n",
      "Epoch 19, Loss: 1.6251\n",
      "Epoch 20, Loss: 1.6166\n",
      "Epoch 21, Loss: 1.6175\n",
      "Epoch 22, Loss: 1.6171\n",
      "Epoch 23, Loss: 1.6137\n",
      "Epoch 24, Loss: 1.6123\n",
      "Epoch 25, Loss: 1.6139\n",
      "Epoch 26, Loss: 1.6081\n",
      "Epoch 27, Loss: 1.6175\n",
      "Epoch 28, Loss: 1.6099\n",
      "Epoch 29, Loss: 1.6098\n",
      "Epoch 30, Loss: 1.6095\n",
      "Epoch 31, Loss: 1.5954\n",
      "Epoch 32, Loss: 1.5914\n",
      "Epoch 33, Loss: 1.6037\n",
      "Epoch 34, Loss: 1.6053\n",
      "Epoch 35, Loss: 1.5993\n",
      "Epoch 36, Loss: 1.6158\n",
      "Epoch 37, Loss: 1.5943\n",
      "Epoch 38, Loss: 1.5869\n",
      "Epoch 39, Loss: 1.5984\n",
      "Epoch 40, Loss: 1.5916\n",
      "Epoch 41, Loss: 1.5862\n",
      "Epoch 42, Loss: 1.5920\n",
      "Epoch 43, Loss: 1.5947\n",
      "Epoch 44, Loss: 1.5980\n",
      "Epoch 45, Loss: 1.5878\n",
      "Epoch 46, Loss: 1.5883\n",
      "Epoch 47, Loss: 1.5980\n",
      "Epoch 48, Loss: 1.5895\n",
      "Epoch 49, Loss: 1.5969\n",
      "Epoch 50, Loss: 1.5893\n",
      "Model saved to E:\\\\03_予測モデル\\\\classification_model.pth\n",
      "Prediction results saved to E:\\\\01_データセット\\\\特徴量C\\\\予測用_結果付きB.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# ===============================\n",
    "# ▶ 読み込み元データの保存場所と予測モデルの保存場所\n",
    "# ▶ 予測モデルが更新されたら、04_学習環境フォルダに移動させること（2025-07-26）\n",
    "# ===============================\n",
    "DATA_DIR = r\"E:\\\\01_データセット\\\\特徴量\\\\\"\n",
    "MODEL_DIR = r\"E:\\\\03_予測モデル\\\\\"\n",
    "\n",
    "# ===============================\n",
    "# ▶ データ読み込み（元データの数をコントロールするために分割して保存している）\n",
    "# ▶ globでファイルを取得している。複数ある場合はpd.concatで合体している\n",
    "# ===============================\n",
    "file_list = glob.glob(os.path.join(DATA_DIR, '特徴量*.csv'))\n",
    "df_list = [pd.read_csv(file, encoding='shift_jis') for file in file_list]\n",
    "df_all = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "#================================\n",
    "# race_id ユニーク化（1レースごとの予測をするためにグループ化している）\n",
    "#================================\n",
    "unique_race_ids = np.arange(1, len(df_all) // 6 + 1).repeat(6)\n",
    "df_all['race_id'] = unique_race_ids\n",
    "\n",
    "# ===============================\n",
    "# ▶ 特徴量 & 目的変数\n",
    "# ===============================\n",
    "# 調整箇所じー(´◉ω◉` )\n",
    "feature_cols = ['motor_win_rate', 'course', 'Zenkoku_power', 'Boat_power']\n",
    "target_col = 'result'\n",
    "\n",
    "# ===============================\n",
    "# 特徴量の調整（コースは小さいほうが強い。特徴量に－をかけて反転している）-->（2025-07-26）－にしないほうが的中率が高かった\n",
    "# ===============================\n",
    "# 調整箇所じー(´◉ω◉` )\n",
    "#df_all['course'] = df_all['course'] * -1\n",
    "\n",
    "# ===============================\n",
    "# 正規化\n",
    "# ===============================\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(df_all[feature_cols])\n",
    "y = df_all[target_col].values - 1  # 0始まりに変換\n",
    "\n",
    "# ===============================\n",
    "# ▶ Dataset 作成\n",
    "# ▶ pytorchのカスタムデータをセットしている。機械学習モデルに渡す特徴量と正解データを定型的な形で提供するための仕組み\n",
    "# ===============================\n",
    "class BoatRaceDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': torch.tensor(self.features[idx], dtype=torch.float32),\n",
    "            'targets': torch.tensor(self.targets[idx], dtype=torch.long)\n",
    "        }\n",
    "# ===============================\n",
    "# データ分割 test_size = 0.3 random_state = 0 --> 2025/07/20 -->0.2にしたほうが的中率があがった -->0.4 -->0.3\n",
    "# ===============================\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 調整箇所じー(´◉ω◉` )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "train_dataset = BoatRaceDataset(X_train, y_train)\n",
    "test_dataset = BoatRaceDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# ===============================\n",
    "# ▶ モデル imput_dim XXX XXX, YYY, YYY ZZZ\n",
    "# ===============================\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "# 調整箇所じー(´◉ω◉` )　下と連動すること→変更したらBoatPy_verXX.pyも連動して変えること。エラーになります。\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 48)\n",
    "        self.fc4 = nn.Linear(48, 32)\n",
    "        self.fc5 = nn.Linear(32, 24)                \n",
    "        self.fc6 = nn.Linear(24, 16)\n",
    "        self.fc7 = nn.Linear(16, 8)\n",
    "        self.output = nn.Linear(8, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "# 調整箇所じー(´◉ω◉` )　上と連動すること\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x)) \n",
    "        x = torch.relu(self.fc6(x))\n",
    "        x = torch.relu(self.fc7(x))          \n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# ===============================\n",
    "# ▶ 訓練　pcにgpuがあるかをチェックしている。gpuがあればcuda、なければcpu\n",
    "# ▶ 自分のニューラルネットワーククラスを用いて、モデルを作成している。出力クラスを6つ（6艇が出走するから）にしている分類問題\n",
    "# ===============================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ClassificationModel(input_dim=X.shape[1], num_classes=6).to(device)\n",
    "# ===============================\n",
    "# ▶ 学習率 lr= 0.001 --> 2025/07/25\n",
    "# ▶ 学習率 lr=\n",
    "# ===============================\n",
    "# 調整箇所じー、学習率(´◉ω◉` )　--> 学習率を0.001から0.0005にしたほうが的中率があがった\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ===============================\n",
    "# 調整箇所じー、エポック(´◉ω◉` )　for epoch in range(50) -->2025/07/25\n",
    "# エポックとは --> 50回繰り返しする --> 30にする\n",
    "# ===============================\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features = batch['features'].to(device)\n",
    "        targets = batch['targets'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}')\n",
    "\n",
    "# ===============================\n",
    "# ▶ モデル保存 --> 初めに指定したMODEL_DIRに作成したモデルを保存している -->実際に使うときは04_学習環境に移動させること\n",
    "# ===============================\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "model_path = os.path.join(MODEL_DIR, 'classification_model.pth')\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'scaler': scaler\n",
    "}, model_path)\n",
    "\n",
    "print(f'Model saved to {model_path}')\n",
    "\n",
    "# ===============================\n",
    "# ▶ 予測 --> モデルの性能を試すために、順位を除いた予測用.csvに適用させる。的中率はエクセルでのちに計算する。\n",
    "# ===============================\n",
    "predict_file = os.path.join(DATA_DIR, '予測用.csv')\n",
    "df_predict = pd.read_csv(predict_file, encoding='shift_jis')\n",
    "\n",
    "X_predict = scaler.transform(df_predict[feature_cols])\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_tensor = torch.tensor(X_predict, dtype=torch.float32).to(device)\n",
    "    outputs = model(X_tensor)\n",
    "    predictions = torch.argmax(outputs, dim=1).cpu().numpy() + 1  # 1始まりに戻す\n",
    "\n",
    "df_predict['result'] = predictions\n",
    "\n",
    "# ===============================\n",
    "# ▶ 順位強制付与（同点の場合はcourseが小さい方を優先 -->内側有利の原則にのっとって）　　\n",
    "# ===============================\n",
    "\n",
    "def rank_with_tiebreaker(df):\n",
    "    results = []\n",
    "    for race_id, group in df.groupby('race_id'):\n",
    "        group = group.copy()\n",
    "        group['rank_score'] = group['result'] + group['course'] * 0.01  # courseで微調整\n",
    "        group['final_rank'] = group['rank_score'].rank(method='first', ascending=True).astype(int)\n",
    "        results.append(group)\n",
    "    return pd.concat(results)\n",
    "\n",
    "df_predict = rank_with_tiebreaker(df_predict)\n",
    "df_predict['result'] = df_predict['final_rank']\n",
    "\n",
    "# ===============================\n",
    "# ▶ 予測用.csvに結果をつけて保存 --> エクセルで分析へ\n",
    "# ===============================\n",
    "\n",
    "predict_result_file = os.path.join(DATA_DIR, '予測用_結果付きB.csv')\n",
    "df_predict.to_csv(predict_result_file, index=False, encoding='utf-8')\n",
    "print(f'Prediction results saved to {predict_result_file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
