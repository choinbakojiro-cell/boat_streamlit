import streamlit as st
import random
import pandas as pd
import time
import requests
from bs4 import BeautifulSoup

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– ---
if "dice_results" not in st.session_state:
    st.session_state.dice_results = None

if "race_data" not in st.session_state:
    st.session_state.race_data = None

# --- ã‚¿ã‚¤ãƒˆãƒ«éƒ¨åˆ† ---
col1, col2, col3 = st.columns([2, 4, 2])

with col1:
    st.image("dog_boat01.png", width=250)

with col2:
    st.markdown("""
        <div style='text-align: center;'>
            <h1 style='font-family: "Yu Mincho", "Hiragino Mincho Pro", "MS PMincho", serif;
                       font-style: italic;
                       color: #C62828;
                       font-size: 32px;
                       margin: 0;'>
            BOATRACE_AI_ver02
            </h1>
        </div>
    """, unsafe_allow_html=True)

with col3:
    st.image("dog_boat02.png", width=250)

# --- ğŸ² æœ¬æ—¥ã®ãƒ©ãƒƒã‚­ãƒ¼ãƒŠãƒ³ãƒãƒ¼ ---
if st.button("ğŸ²æœ¬æ—¥ã®ãƒ©ãƒƒã‚­ãƒ¼ãƒŠãƒ³ãƒãƒ¼ ï¼"):
    with st.spinner("ğŸ¥ ãƒ‰ã‚³ãƒ‰ã‚³ãƒ‰ã‚³ãƒ‰ã‚³..."):
        time.sleep(2)
    triplets = []
    used = set()
    while len(triplets) < 6:
        comb = sorted(random.sample(range(1, 7), 3))
        if tuple(comb) not in used:
            triplets.append(comb)
            used.add(tuple(comb))
    df = pd.DataFrame({"çµ„ã¿åˆã‚ã›": [f"{x[0]}-{x[1]}-{x[2]}" for x in triplets]})
    st.session_state.dice_results = df  # çµæœã‚’ä¿å­˜

# --- ğŸ² çµæœè¡¨ç¤ºï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ã€æ¨ªä¸¦ã³ã«ã€ãŠè¨€è‘‰è¡¨ç¤ºï¼‰ ---
if st.session_state.dice_results is not None:
    st.subheader("ğŸ² ã‚µã‚¤ã‚³ãƒ­å ã„")

    # ãŠè¨€è‘‰.csv èª­ã¿è¾¼ã¿ï¼ˆAåˆ—:çµ„ã¿åˆã‚ã›æ–‡å­—åˆ—ã€Båˆ—:è¨€è‘‰ï¼‰
    words_df = pd.read_csv("ãŠè¨€è‘‰.csv", dtype=str)
    words_dict = dict(zip(words_df.iloc[:, 0], words_df.iloc[:, 1]))  # è¾æ›¸åŒ–

    cols = st.columns(6)  # 6åˆ—ã«åˆ†å‰²
    for i, col in enumerate(cols):
        combination = st.session_state.dice_results.iloc[i, 0]  # çµ„ã¿åˆã‚ã›æ–‡å­—åˆ—
        message = words_dict.get(combination, "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãªã—")  # å®Œå…¨ä¸€è‡´ã§å–å¾—

        # çµ„ã¿åˆã‚ã›ã¨ãŠè¨€è‘‰ã‚’è¡¨ç¤º
        col.markdown(
            f"""
            <div style='background-color: #b3e5fc; padding: 10px; border-radius: 8px; text-align: center; font-weight: bold;'>
                {combination}
            </div>
            <div style='margin-top: 10px; text-align: center; font-size: 14px;'>
                {message}
            </div>
            """,
            unsafe_allow_html=True
        )


##ã“ã“ã‹ã‚‰
import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import datetime

# --- ç«¶è‰‡å ´ãƒªã‚¹ãƒˆ ---
boat_places = {
    "æ¡ç”Ÿ": "01", "æˆ¸ç”°": "02", "æ±Ÿæˆ¸å·": "03", "å¹³å’Œå³¶": "04", "å¤šæ‘©å·": "05",
    "æµœåæ¹–": "06", "è’²éƒ¡": "07", "å¸¸æ»‘": "08", "æ´¥": "09", "ä¸‰å›½": "10",
    "ã³ã‚ã“": "11", "ä½ä¹‹æ±Ÿ": "12", "å°¼å´": "13", "é³´é–€": "14", "ä¸¸äº€": "15",
    "å…å³¶": "16", "å®®å³¶": "17", "å¾³å±±": "18", "ä¸‹é–¢": "19", "è‹¥æ¾": "20",
    "èŠ¦å±‹": "21", "ç¦å²¡": "22", "å”æ´¥": "23", "å¤§æ‘": "24"
}

# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼é¸æŠ ---
st.subheader("ğŸ äºˆæƒ³ã—ãŸã„ãƒ¬ãƒ¼ã‚¹ã‚’é¸æŠ")
selected_place = st.selectbox("ç«¶è‰‡å ´ã‚’é¸æŠ", list(boat_places.keys()))
selected_race = st.selectbox("ãƒ¬ãƒ¼ã‚¹ç•ªå·ã‚’é¸æŠ", [f"{i}R" for i in range(1, 13)])
selected_date = st.date_input("æ—¥ä»˜ã‚’é¸æŠ", value=datetime.date.today())

# --- å‡ºèµ°è¡¨URLç”Ÿæˆ ---
jcd = boat_places[selected_place]
rno = selected_race.replace("R", "")
hd = selected_date.strftime("%Y%m%d")
detail_url = f"https://www.boatrace.jp/owpc/pc/race/racelist?rno={rno}&jcd={jcd}&hd={hd}"

# --- å‡ºèµ°è¡¨URLã‚’è¡¨ç¤º ---
if st.button("å‡ºèµ°è¡¨URLã‚’è¡¨ç¤º"):
    st.markdown(f"ğŸ”— [å‡ºèµ°è¡¨URLã¯ã“ã¡ã‚‰]({detail_url})", unsafe_allow_html=True)

# --- é¸æ‰‹æƒ…å ±å–å¾—é–¢æ•° ---
def get_race_data_from_url(url):
    headers = {"User-Agent": "Mozilla/5.0"}
    res = requests.get(url, headers=headers)
    res.raise_for_status()
    soup = BeautifulSoup(res.content, "html.parser")

    tbodies = soup.find_all("tbody", class_="is-fs12")
    racers = []

    for tbody in tbodies:
        tr = tbody.find("tr")
        if not tr:
            continue
        tds = tr.find_all("td")
        if len(tds) < 7:
            continue

        try:
            reg_info = tds[2].find("div", class_="is-fs11")
            reg_num = reg_info.text.split("/")[0].strip()
            grade = reg_info.find("span").text.strip() if reg_info.find("span") else ""

            winrate = tds[4].text.strip().split("\n")[0]
            motor_info = tds[6].text.strip().split("\n")
            motor_rate = motor_info[1] if len(motor_info) > 1 else ""

            racers.append({
                "ç™»éŒ²ç•ªå·": reg_num,
                "ç´šåˆ¥": grade,
                "å…¨å›½å‹ç‡": winrate,
                "ãƒ¢ãƒ¼ã‚¿ãƒ¼2é€£ç‡": motor_rate
            })
        except:
            continue

    return pd.DataFrame(racers) if racers else None

# --- URLã‹ã‚‰é¸æ‰‹æƒ…å ±å–å¾— ---
st.subheader("ğŸ”— å‡ºèµ°è¡¨URLã‹ã‚‰é¸æ‰‹æƒ…å ±ã‚’å–å¾—")
st.caption("ç´šåˆ¥ãƒ©ãƒ³ã‚¯ã®å¤‰æ›: A1=1, A2=0.7, B1=0.4, B2=0.1")  # â† è¡¨ç¤ºè¿½åŠ 

input_url = st.text_input("å‡ºèµ°è¡¨ã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", placeholder=detail_url)

if st.button("ğŸ‘€ æƒ…å ±ã‚’å–å¾—"):
    if not input_url:
        st.warning("âš  URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        try:
            df = get_race_data_from_url(input_url)

            if df is not None:
                grade_mapping = {"A1": 1.0, "A2": 0.7, "B1": 0.4, "B2": 0.1}
                df["ç´šåˆ¥ãƒ©ãƒ³ã‚¯"] = df["ç´šåˆ¥"].map(grade_mapping).fillna(0)
                st.session_state.df = df  # ğŸ”¶ ã“ã“ã‚’è¿½åŠ ï¼šã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
                st.success("âœ… å‡ºèµ°é¸æ‰‹ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ")
                st.dataframe(df)
            else:
                st.warning("âš  é¸æ‰‹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚URLã‚„ãƒšãƒ¼ã‚¸æ§‹é€ ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        except Exception as e:
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")

#ã“ã“ã‹ã‚‰äºˆæ¸¬########################################################################################
import itertools
import torch
import os
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import streamlit as st
import torch.nn as nn

# ğŸ” å®‰å…¨ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ˜ç¤ºçš„ã«è¨±å¯
torch.serialization.add_safe_globals([
    StandardScaler,
    np.dtype,
    np.core.multiarray._reconstruct,
    np.core.multiarray
])

# --- ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®èª­ã¿è¾¼ã¿é–¢æ•° ---
@st.cache_resource
def load_model_and_scaler(model_path):
    checkpoint = torch.load(model_path, weights_only=False, map_location='cpu')
    model_state = checkpoint['model_state_dict']
    scaler = checkpoint['scaler']

    class ClassificationModel(torch.nn.Module):
        def __init__(self, input_dim, num_classes):
            super().__init__()
            self.fc1 = nn.Linear(input_dim, 128)
            self.fc2 = nn.Linear(128, 64)
            self.fc3 = nn.Linear(64, 32)
            self.output = nn.Linear(32, num_classes)

        def forward(self, x):
            x = torch.relu(self.fc1(x))
            x = torch.relu(self.fc2(x))
            x = torch.relu(self.fc3(x))
            x = self.output(x)
            return x

    model = ClassificationModel(input_dim=4, num_classes=6)
    model.load_state_dict(model_state)
    model.eval()

    return model, scaler

# --- ãƒ‘ã‚¹æŒ‡å®šã¨ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ ---
MODEL_PATH = r"E:\04_å­¦ç¿’ç’°å¢ƒ\classification_model.pth"
if not os.path.exists(MODEL_PATH):
    st.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {MODEL_PATH}")
    st.stop()

model, scaler = load_model_and_scaler(MODEL_PATH)

# --- ç‰¹å¾´é‡æ•´å½¢ãƒ»äºˆæ¸¬å‡¦ç† ---
if 'df' in st.session_state:
    df = st.session_state.df.copy()

    # ã‚³ãƒ¼ã‚¹å‰²ã‚Šå½“ã¦ï¼ˆ1ã€œ6ï¼‰
    df["course"] = [i + 1 for i in range(len(df))]

    # ç‰¹å¾´é‡æ•´å‚™
    df["Rank"] = df["ç´šåˆ¥ãƒ©ãƒ³ã‚¯"]
    df["Zenkoku_power"] = pd.to_numeric(df["å…¨å›½å‹ç‡"], errors='coerce').fillna(0)
    df["motor_win_rate"] = df["ãƒ¢ãƒ¼ã‚¿ãƒ¼2é€£ç‡"].str.replace('%', '').astype(float)
    df["course"] = -df["course"] * 2  # å°ã•ã„æ–¹ãŒå¼·ã„ã®ã§åè»¢

    # ç‰¹å¾´é‡ã¨å¤‰æ›
    feature_cols = ["motor_win_rate", "course", "Rank", "Zenkoku_power"]
    X = scaler.transform(df[feature_cols])
    X_tensor = torch.tensor(X, dtype=torch.float32)

    with torch.no_grad():
        outputs = model(X_tensor)
        predicted_ranks = outputs.argmax(dim=1).numpy()  # å‡ºåŠ›ãŒ6ã‚¯ãƒ©ã‚¹åˆ†é¡ï¼ˆ0=1ä½, ..., 5=6ä½ï¼‰

    df["äºˆæ¸¬ç€é †ã‚¹ã‚³ã‚¢"] = predicted_ranks
    df_sorted = df.sort_values(by="äºˆæ¸¬ç€é †ã‚¹ã‚³ã‚¢").reset_index(drop=True)

    st.subheader("ğŸ¯ ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬é †ä½ï¼ˆä¸Šä½3åï¼‰")
    st.dataframe(df_sorted[["ç™»éŒ²ç•ªå·", "ç´šåˆ¥", "å…¨å›½å‹ç‡", "ãƒ¢ãƒ¼ã‚¿ãƒ¼2é€£ç‡", "äºˆæ¸¬ç€é †ã‚¹ã‚³ã‚¢"]].head(3))

#    top3 = df_sorted.iloc[:3]["ç™»éŒ²ç•ªå·"].tolist()
#    combinations = list(itertools.permutations(top3, 3))

#    st.subheader("ğŸ° 3é€£å˜äºˆæ¸¬ï¼ˆ6é€šã‚Šï¼‰")
#    for comb in combinations:
#        st.write(" â†’ ".join(comb))

#    top3 = (df_sorted.iloc[:3]["course"] * -0.5).astype(int).tolist()
#    combinations = list(itertools.permutations(top3, 3))

#    st.subheader("ğŸ° 3é€£å˜äºˆæ¸¬ï¼ˆã‚³ãƒ¼ã‚¹ç•ªå·ãƒ™ãƒ¼ã‚¹ï¼‰")
#    for comb in combinations:
#        st.write(" â†’ ".join(map(str, comb)))
# ã‚³ãƒ¼ã‚¹ç•ªå·ï¼ˆ1ã€œ6ï¼‰ã«æˆ»ã™
    top3 = (df_sorted.iloc[:3]["course"] * -0.5).astype(int).tolist()

    # 3é€£å˜ã®å…¨çµ„ã¿åˆã‚ã›ã‚’ä½œæˆï¼ˆé †åˆ—ï¼‰
    combinations = list(itertools.permutations(top3, 3))

    # DataFrameã«å¤‰æ›ï¼ˆåˆ—åã‚’æŒ‡å®šï¼‰
    df_combinations = pd.DataFrame(combinations, columns=["1ç€", "2ç€", "3ç€"])

    # è¡¨å½¢å¼ã§è¡¨ç¤º
    st.subheader("ğŸ° 3é€£å˜äºˆæ¸¬ï¼ˆã‚³ãƒ¼ã‚¹ç•ªå·ãƒ™ãƒ¼ã‚¹ï¼‰")
    st.dataframe(df_combinations)

else:
    st.warning("âš  å…ˆã«å‡ºèµ°é¸æ‰‹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚")